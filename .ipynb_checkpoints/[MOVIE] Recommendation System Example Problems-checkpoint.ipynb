{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
    "              [np.NaN, 5, np.NaN, 3, 1],\n",
    "              [np.NaN,np.NaN,3,4,4],\n",
    "              [5,2,1,2,np.NaN]])\n",
    "\n",
    "num_users, num_items = R.shape\n",
    "\n",
    "#latent dimension k\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "# Make P,Q with number with nurmal distribution\n",
    "P = np.random.normal(scale =1./k, size =(num_users, k))\n",
    "Q = np.random.normal(scale = 1./k, size =(num_items, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.36187687,  0.33244848,  0.09432617],\n",
       "        [-0.50209824, -0.19286675,  0.55047885],\n",
       "        [-0.80889308, -0.14297088,  0.42197875],\n",
       "        [-0.28891347, -0.22629538, -0.03156966]]),\n",
       " array([[ 0.49712988, -0.21296733, -0.14799399],\n",
       "        [-0.14478376,  0.73531003,  0.7289287 ],\n",
       "        [ 0.33468463,  0.1287288 ,  0.24578953],\n",
       "        [ 0.49691068, -0.31194462,  0.39194301],\n",
       "        [-0.41796022, -0.21258383,  0.3023684 ]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss RMSE\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    \n",
    "    full_pred_matrix = np.dot(P,Q.T)\n",
    "    \n",
    "    # from R extract Non null value and calculate RMSE\n",
    "    row_non_zero_idx = [non_zero[0] for non_zero in non_zeros] #row idx\n",
    "    col_non_zero_idx = [non_zero[1] for non_zero in non_zeros] #column idx\n",
    "    \n",
    "    R_non_zeros = R[row_non_zero_idx, col_non_zero_idx]\n",
    "    \n",
    "    #extract non null values from predicted matrix\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[row_non_zero_idx, col_non_zero_idx]\n",
    "    \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    \n",
    "    return rmse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'non_zeros' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6f329bcd3146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Update P and Q with SGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnon_zeros\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;31m#error rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0meij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'non_zeros' is not defined"
     ]
    }
   ],
   "source": [
    "# non_zeros = [(i,j,R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] >0]\n",
    "\n",
    "steps = 1000\n",
    "learning_rate = 0.01\n",
    "r_lambda = 0.01\n",
    "\n",
    "#Update P and Q with SGD\n",
    "for step in range(steps):\n",
    "    for i,j,r in non_zeros:\n",
    "        #error rate\n",
    "        eij = r - np.dot(P[i,:],Q[j,:].T)\n",
    "        #SGD Update Formula\n",
    "        P[i, :] = P[i,:] + learning_rate * (eij * Q[j, :] - r_lambda * P[i,:])\n",
    "        Q[j, :] = Q[j,:] + learning_rate * (eij * P[i, :] - r_lambda * Q[j,:])\n",
    "        \n",
    "        rmse = get_rmse(R,P,Q, non_zeros)\n",
    "        \n",
    "        if(step % 10) == 0:\n",
    "            print(\" ### iteration step : \",step,\" rmse : \", rmse)      \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_matrix = np.dot(P,Q.T)\n",
    "print('predicted matrix:\\n',np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB Movie Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Genre for Content Based Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "print(movies.shape)\n",
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies[['id', 'title', 'genres', 'vote_average','vote_count',\n",
    "                   'popularity','keywords','overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "movies_df[['genres','keywords']][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert genres to list\n",
    "from ast import literal_eval\n",
    "\n",
    "movies_df['genres'] = movies_df['genres'].apply(literal_eval)\n",
    "movies_df['keywords'] = movies_df['keywords'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genres'][:1], movies_df['keywords'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only genre name\n",
    "movies_df['genres'] = movies_df['genres'].apply(lambda x: [y['name'] for y in x])\n",
    "movies_df['keywords'] = movies_df['keywords'].apply(lambda x: [y['name'] for y in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['genres','keywords']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content Similarity Using CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "movies_df['genres_literal'] = movies_df['genres'].apply(lambda x : (' ').join(x))\n",
    "count_vect = CountVectorizer(min_df = 0, ngram_range = (1,2))\n",
    "genre_mat = count_vect.fit_transform(movies_df['genres_literal'])\n",
    "print(genre_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vars(genre_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#represent genre's similarity each other\n",
    "genre_sim = cosine_similarity(genre_mat, genre_mat)\n",
    "print(genre_sim.shape)\n",
    "genre_sim\n",
    "temp = pd.DataFrame(genre_sim)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use argsort to find index of higher similarity row\n",
    "\n",
    "genre_sim_sorted_idx = genre_sim.argsort()[:, ::-1]\n",
    "genre_sim_sorted_idx[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim_movie(df, sorted_idx, title, top_n =10):\n",
    "    title_movie = df[df['title'] == title]\n",
    "    \n",
    "    title_idx = title_movie.index.values\n",
    "    similar_indexes = sorted_idx[title_idx, :top_n]\n",
    "    \n",
    "    print(similar_indexes)\n",
    "    similar_indexes = similar_indexes.reshape(-1)\n",
    "    \n",
    "    return df.iloc[similar_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_idx, 'The Godfather', 10)\n",
    "similar_movies[['title','vote_average']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['title', 'vote_average', 'vote_count']].sort_values('vote_average', ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USE WEIGHTED RATING USED BY IMDB\n",
    "v : vote_count\n",
    "m : minimum_count\n",
    "R : vote_average of each movie\n",
    "C : average rating of total movie rating\n",
    "\"\"\"\n",
    "\n",
    "C = movies_df['vote_average'].mean()\n",
    "m = movies_df['vote_count'].quantile(0.6) # top 60%\n",
    "round(C, 3) , round(m,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 0.6\n",
    "m = movies_df['vote_count'].quantile(percentile)\n",
    "C = movies_df['vote_average'].mean()\n",
    "\n",
    "def weighted_vote_average(record):\n",
    "    v = record['vote_count']\n",
    "    R = record['vote_average']\n",
    "    \n",
    "    return ((v/(v+m)) * R) + ((m/(m+v)) * C )\n",
    "\n",
    "movies_df['weighted_vote'] = movies_df.apply(weighted_vote_average, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies[['title','vote_average','vote_count','weighted_vote']].sort_values('weighted_vote', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim_movie(df, sorted_idx, title, top_n =10):\n",
    "    title_movie = df[df['title'] == title]\n",
    "    title_idx = title_movie.index.values\n",
    "    \n",
    "    similar_indexes = sorted_idx[title_idx, :top_n*2]\n",
    "    similar_indexes = similar_indexes.reshape(-1)\n",
    "    #delete input title\n",
    "    similar_indexes = similar_indexes[similar_indexes != title_idx]\n",
    "    \n",
    "    return df.iloc[similar_indexes].sort_values('weighted_vote', ascending = False)[:top_n]\n",
    "\n",
    "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_idx, 'The Godfather', 10)\n",
    "similar_movies[['title','vote_average','weighted_vote']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('Movielens/movies.csv')\n",
    "ratings = pd.read_csv('Movielens/ratings.csv')\n",
    "movies.shape , ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "ratings_matrix = ratings.pivot_table('rating', index = 'userId', columns = 'movieId')\n",
    "ratings_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_movies = pd.merge(ratings, movies, on ='movieId')\n",
    "\n",
    "ratings_matrix = rating_movies.pivot_table('rating', index = 'userId', columns = 'title')\n",
    "\n",
    "ratings_matrix = ratings_matrix.fillna(0)\n",
    "ratings_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity between Movies\n",
    "\n",
    "ratings_matrix_T = ratings_matrix.transpose()\n",
    "ratings_matrix_T.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim = cosine_similarity(ratings_matrix_T, ratings_matrix_T)\n",
    "\n",
    "item_sim_df = pd.DataFrame(data = item_sim, index = ratings_matrix.columns, columns = ratings_matrix.columns)\n",
    "\n",
    "print(item_sim_df.shape)\n",
    "item_sim_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_df['Godfather, The (1972)'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_df['Inception (2010)'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_rating(ratings_arr, item_sim_arr):\n",
    "    ratings_pred = ratings_arr.dot(item_sim_arr)/np.array([np.abs(item_sim_arr).sum(axis=1)])\n",
    "    return ratings_pred\n",
    "\n",
    "ratings_pred = predict_rating(ratings_matrix.values, item_sim_df.values)\n",
    "ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index = ratings_matrix.index, columns = ratings_matrix.columns)\n",
    "\n",
    "ratings_pred_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n",
    "\n",
    "get_mse(ratings_pred, ratings_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predic_rating uses all movies similarities which makes accuracy lower\n",
    "# make function to use movies have higher similarities\n",
    "\n",
    "def predict_rating_topsim(ratings_arr, item_sim_arr, n =20):\n",
    "    \n",
    "    pred = np.zeros(ratings_arr.shape)\n",
    "    \n",
    "    for col in range(ratings_arr.shape[1]):\n",
    "        top_n_items = [np.argsort(item_sim_arr[:,col])[:-n-1:-1]]\n",
    "        \n",
    "        for row in range(ratings_arr.shape[0]):\n",
    "            pred[row, col] = item_sim_arr[col, :][top_n_items].dot(ratings_arr[row,:][top_n_items].T)\n",
    "            pred[row, col] /= np.sum(np.abs(item_sim_arr[col,:][top_n_items]))\n",
    "            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pred = predict_rating_topsim(ratings_matrix.values, item_sim_df.values, n =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 mse\n",
    "print(get_mse(ratings_pred, ratings_matrix.values))\n",
    "\n",
    "ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index = ratings_matrix.index, columns = ratings_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating_id = ratings_matrix.iloc[9,:]\n",
    "user_rating_id[user_rating_id>0].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unseen_movies(ratings_matrix, userId):\n",
    "    user_rating = ratings_matrix.loc[userId, :]\n",
    "    \n",
    "    already_seen = user_rating[user_rating>0].index.tolist()\n",
    "    \n",
    "    movies_list = ratings_matrix.columns.tolist()\n",
    "    \n",
    "    unseen_list = [movie for movie in movies_list if movie not in already_seen]\n",
    "    \n",
    "    return unseen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movie_by_userId(pred_df, userId, unseen_list, top_n =10):\n",
    "    \n",
    "    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
    "    return recomm_movies\n",
    "\n",
    "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
    "\n",
    "recomm_movies = recommend_movie_by_userId(ratings_pred_matrix, 9, unseen_list, top_n = 20)\n",
    "\n",
    "recomm_movies = pd.DataFrame(recomm_movies.values, index = recomm_movies.index, columns =['pred_score'])\n",
    "\n",
    "recomm_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Collaborative Filtering Using Matrix Factorization (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss RMSE\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    \n",
    "    full_pred_matrix = np.dot(P,Q.T)\n",
    "    \n",
    "    # from R extract Non null value and calculate RMSE\n",
    "    row_non_zero_idx = [non_zero[0] for non_zero in non_zeros] #row idx\n",
    "    col_non_zero_idx = [non_zero[1] for non_zero in non_zeros] #column idx\n",
    "    \n",
    "    R_non_zeros = R[row_non_zero_idx, col_non_zero_idx]\n",
    "    \n",
    "    #extract non null values from predicted matrix\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[row_non_zero_idx, col_non_zero_idx]\n",
    "#     print(R_non_zeros)\n",
    "#     print(full_pred_matrix_non_zeros)\n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    \n",
    "    return rmse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=2000, learning_rate = 0.01, r_lambda = 0.01):\n",
    "    num_users, num_items = R.shape\n",
    "    \n",
    "    np.random.seed(123)\n",
    "    P = np.random.normal(scale = 1./K, size=(num_users, K))\n",
    "    Q = np.random.normal(scale = 1./K, size=(num_items, K))\n",
    "    \n",
    "    prev_rmse = 10000\n",
    "    break_point = 0\n",
    "    \n",
    "    non_zeros = [(i,j,R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] >0]\n",
    "\n",
    "    \n",
    "    #SGD\n",
    "    for step in range(steps):\n",
    "        for i, j , r in non_zeros:\n",
    "            \n",
    "            eij = r - np.dot(P[i, :], Q[j,:].T)\n",
    "            \n",
    "            P[i, :] = P[i, :] + learning_rate * (eij * Q[j, :] - r_lambda * P[i, :])\n",
    "            Q[j, :] = Q[j, :] + learning_rate * (eij * P[i, :] - r_lambda * Q[j, :])\n",
    "            \n",
    "        rmse = get_rmse(R, P, Q, non_zeros)\n",
    "        if(step % 10) == 0:\n",
    "            print(\"### iteration step : \",step,\" rmse : \", rmse)\n",
    "    \n",
    "    return P,Q    \n",
    "\n",
    "non_zeros = [(i,j,R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] >0]\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('Movielens/movies.csv')\n",
    "ratings = pd.read_csv('Movielens/ratings.csv')\n",
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "ratings_matrix = ratings.pivot_table('rating', index = 'userId', columns = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_movies = pd.merge(ratings, movies, on ='movieId')\n",
    "ratings_matrix = rating_movies.pivot_table('rating', index = 'userId', columns ='title')\n",
    "ratings_matrix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P,Q = matrix_factorization(ratings_matrix.values, K=50, steps =1000, learning_rate = 0.01, r_lambda = 0.01)\n",
    "\n",
    "pred_matrix = np.dot(P, Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pred_matrix = pd.DataFrame(data = pred_matrix, index = ratings_matrix.index, columns = ratings_matrix.columns)\n",
    "\n",
    "ratings_pred_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unseen_movies(ratings_matrix, userId):\n",
    "    user_rating = ratings_matrix.loc[userId, :]\n",
    "    \n",
    "    already_seen = user_rating[user_rating>0].index.tolist()\n",
    "    \n",
    "    movies_list = ratings_matrix.columns.tolist()\n",
    "    \n",
    "    unseen_list = [movie for movie in movies_list if movie not in already_seen]\n",
    "    \n",
    "    return unseen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movie_by_userId(pred_df, userId, unseen_list, top_n =10):\n",
    "    \n",
    "    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
    "    return recomm_movies\n",
    "\n",
    "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
    "\n",
    "recomm_movies = recommend_movie_by_userId(ratings_pred_matrix, 9, unseen_list, top_n = 20)\n",
    "\n",
    "recomm_movies = pd.DataFrame(recomm_movies.values, index = recomm_movies.index, columns =['pred_score'])\n",
    "\n",
    "recomm_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
    "\n",
    "recomm_movies = recommend_movie_by_userId(ratings_pred_matrix, 9, unseen_list, top_n=20)\n",
    "\n",
    "recomm_movies = pd.DataFrame(data = recomm_movies.values, index = recomm_movies.index, columns = ['pred_score'])\n",
    "recomm_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
